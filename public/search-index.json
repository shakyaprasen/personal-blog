[{"slug":"5-crucial-things-I-do","category":"blog","title":"5 crucial things that I do before deploying my code","description":"This is a blog post on five things I do before deploying my code as a developer.","tags":["programming habits","productivity","steps"],"body":"\nOn my tech journey, I have tried to learn everything I can. Though my journey has not been too long, I have developed some habits - some subconsciously, some deliberately, some good, some let's say… not so good. Not only me, but I have observed this to be true of my peers and friends as well. Thinking about this led me to write a short blog about one of the many habits that I have delivered on my journey to become a developer.\n\nFirst things first, every developer has something to do before deploying their code. So, here I am writing about the 5 things I do before deploying my code.\n\n*Here is the tldr:*\n\n*The 5 steps I follow before deploying any code:*\n\n- *Check if the finished code fulfills the requirements/user story*\n- *Compare the changes to the code*\n- *Test the functionality on local/ staging server*\n- *Make sure all the code review comments are addressed*\n- *Make sure the automated tests have passed*\n\n\n## Check if the finished code fulfills the requirements/user story\nThe first thing that I always do before even thinking about committing and pushing my code is making sure my code works as intended. Even before testing edge cases, I make sure that my code fulfills the users requirements or user story.\n\n## Compare the changes to the code\nAfter the first step, I compare the changes to every file that I have made. This step helps me spot any errors like typos or missed console logs as well as re-evaluate any logic/ statements - so that I can make it cleaner/ simpler.\n\n## Test the functionality on local/ staging server\nImmediately after rechecking, I push my code to the cloud and test the functionality on the staging server to check if any thing might be broken on non-local environment.\n\n## Make sure all the code review comments are addressed\nMeanwhile, in between steps 2 and 3, I always keep the comments in the code review in mind and address them. Sometimes, I learn new things and ways to better my code, other times I find things that i have missed.\n\n## Make sure the automated tests have passed\nFinally, before deploying-merging I check to see if the CI tests like those of Code Climate have passed. These CI tests make sure that the code adheres to the standards of the project.\n\nSo, these are the sort of the general checklists that I follow before deploying my code. Different people might have different checklists or things that they do and these things might differ based on the tech stack or between organizations or even between individuals.\n\n\n"},{"slug":"implement-push-notification-using-Amazon-SNS","category":"blog","title":"Implement push notification using Amazon's SNS","description":"How I implemented push notification system using Amazon's SNS","tags":["how to","amazon sns","push notification","aws","mobile development","ios","android"],"body":"Instead of the normal technical article, I want to structure this as a short \"story\" - my story - of how I struggled and eventually succeeded in using Simple Notification Service(SNS) to use for push notification. \n\nWhile trying to use SNS to easily send push notifications, I found it difficult to find good resources detailing the use of SNS + Firebase Cloud Messaging (hence onwards referred to as FCM) on the big ol' internet. I'm writing this story so that lost souls like me will have a relatively easier time implementing it.\n\nBut, before I bombard you with the technical mumbo-jumbo, let's start with the question \"Why use SNS for push notification?\". If you know about push notifications or have implemented push notifications before, you might be thinking \"Why not just use FCM directly\", instead of using an additional layer on top FCM. And to that I say, \"huh, good question\". \n\nMy team decided early on, before starting any work on push notification, to try and minimize external dependencies. Adding to the fact that all of the infrastructure was hosted on AWS and we were already using other AWS services such as S3, SES, etc. it was a conscious choice made to better the developer experience and easy onboarding of other developers to the feature.\n\nSo, I started my journey to implement push notification in the application I was working on (Side note: the application and the domain do not have any significant impact to the story so I'll leave it vague). I only had a basic idea of what push notification even was. So, off I went googling \"What is push notification\" and \"How to implement push notification in SNS\".\n\nThis was the first mistake I made, specifically searching \"How to implement push notification in SNS\". Skimming through the result I found myself thinking \"Sweet, this is easy SNS can directly send a push notification to the mobile phone, this should be easy\". I follow a few steps that I found in the docs and reach my first hurdle. While creating a platform application endpoint, it asks for the push notification platform. \n\nI'm thinking I made a mistake as I don't see this being mentioned in other articles as well. That's when I find out SNS in isolation cannot send push notifications by itself but another service like Apple Push Notification (APN) Service or FCM sends the push to the devices.\n\nWith this knowledge in hand, I continue to follow the steps detailed in the AWS SNS documentation. I first setup a test Firebase account and add my mobile app to the firebase project, following the instructions of the google documentation. I then use the server key from the cloud messaging tab to the create platform application screen in amazon SNS.\n\n![FCM setup](https://imgur.com/lkEuesl.png)\n\nWell that's all well and done, now all there's left is to add the device token (Unique device id to identify each device) and send the push notification.\n\n![Push tests](https://imgur.com/Vlh9TQ5.png)\n\nNow, the next thing left to do was just send a message using the AWS sdk to SNS and the SNS should in theory forward it to Google Cloud Messaging (GCM), and it should handle the rest.\n\nWhile sending the message to GCM, AWS documentation gives lots of options for message formatting for each type of platform(iOS and Android). I had to find out the hard way that since we are sending the push notification first to GCM and only then to the user's device, I needed to send the message to GCM specifically without regard to the platform. \n\nThe final message needed to be JSON stringified before sending and looked something like this:\n\n```javascript\n    const gcm = {\n      notification: {\n        body: 'Hello this is a test message description.',\n        title: 'You got a push notification!',\n      },\n    };\n    const payload = {\n      default: 'This is a default message.',\n      GCM: JSON.stringify(gcm),\n    };\n\n    const stringifiedPayload = JSON.stringify(payload);\n```\n\nI was almost done with the push notification well, not quite. Installing the application to an Android phone and testing the feature through the new notification option under cloud messaging in Firebase console and seemed to work. But, making it work on iOS devices was a whole another story for next time.\n\n\n\n"},{"slug":"run-mysql-on-kubernetes","category":"blog","title":"Run MySQL database on kubernetes","description":"A simple how to on running an instance of MySQL database on a Kubernetes cluster","tags":["how to","dev ops","mysql","kuberentes"],"body":"\n## Background  \n\nA couple of months back, I had to migrate a MySQL server on AWS Relational \nDatabase Service(RDS) to our Kubernetes cluster on AWS Elastic Kubernetes \nService(EKS).\nThis post serves as a how to guide as well as a reminder to myself in case I \nhave do something like this again.\n\n## Mysql Deployment\n\nFirst things first, for running our own MySQL instance we need to create a \ndeployment. A deployment in Kubernetes is just a configuration to express the\ndesired state for a Pod or ReplicaSet.\n\nSo, our deployment config *mysql/deployment.yaml* should look something like\nthis:\n\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-database\nspec:\n  selector:\n    matchLabels:\n      app: mysql-database\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: mysql-database\n    spec:\n      containers:\n        - image: mysql:8.0\n          name: mysql-database\n          env:\n            - name: MYSQL_ROOT_PASSWORD\n              value: ${MYSQL_ROOT_PASSWORD}\n            - name: MYSQL_USER\n              value: ${MYSQL_USERNAME}\n            - name: MYSQL_PASSWORD\n              value: ${MYSQL_PASSWORD}\n            - name: MYSQL_DATABASE\n              value: my_database\n          ports:\n            - containerPort: 3306\n              name: mysql-database\n```\n\nThe above config creates a deployment with mysql version 8.0 image from \nthe official Dockerhub. The variables *${MYSQL_ROOT_PASSWORD}, \n${MYSQL_PASSWORD}, ${MYSQL_USERNAME}* should be populated preferrably using \nkubernetes secrets.\n\nAfter changing the mentioned variables, you can run *kubectl apply -f \n./mysql/deployment.yaml* to run the mysql deployment.\n\n\n## Mysql Service\n\nSo, the mysql deployment is up and running, now how do our pods and services \ninside the Kubernetes cluster connect to the running MySQL server? The answer is easy,\nKubernetes Service. A Kuberentes Service exposes an application, in our case \nthe MySQL server to othe applications.\n\nLet's write the Service config *mysql/service.yaml*:\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: mysql-database\nspec:\n  ports:\n    - port: 3306\n  selector:\n    app: mysql-database\n  clusterIP: None\n\n```\n\nRun *kubectl apply -f .mysql/service.yaml* to run the service.\n\nThis exposes the MySQL server so that other applications/services can connect \nusing the 3306 port on *mysql-database* service name.\n\n\n### Persistent Volume\n\nThe last thing that we missed is to configure the MySQL server so that even if\nthe server restarts, our data does not dissapear. In our current configuration,\nwe have not specified the place to store our data in case of restarts. \nPersistent Volume is a way in Kuberentes to store data in a persistent way. \nIt provides an API to store data independent of the type of data storage \ni.e. Block Storage, NFS, etc and independent of the lifecycle of any pod that\nuses it.\n\nIn short, we will be utilizing Persistent Volume(PV) and \nPersistent Volume Claims(PVC) features of Kuberentes to store data in AWS\nElastic Block Storage. We will also be utilizing Dynamic Volume Provisioning to\nbe able to request dynamically provisioned storage using Storage Class. This\nallows storage volumes to be created on demand.\n\nSo, let's first create our storage class to *storage-class.yaml* which states \nwhat type of storage we will be using.\n\n```yaml\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: standard\nprovisioner: kubernetes.io/aws-ebs\nparameters:\n  type: gp2\nreclaimPolicy: Retain\nallowVolumeExpansion: true\nmountOptions:\n  - debug\nvolumeBindingMode: Immediate\n```\n\nRun *kubectl apply -f ./storage-class.yaml* to create a storage class with the\nabove configuration.\n\n__Note: If you are running this config in your local kuberentes cluster like on a\nMinikube or Docker Desktop, you will have to change the provisioner to \n*k8s.io/minikube-hostpath* or *docker.io/hostpath* depending on where the cluster\nis hosted in your local system.__\n\n```yaml\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: standard\nprovisioner: docker.io/hostpath \nreclaimPolicy: Retain\nallowVolumeExpansion: true\nmountOptions:\n  - debug\nvolumeBindingMode: Immediate\n```\n\nThen we will be creating only a Persistent Volume Claim using the name of the\nStorage Class previously defined i.e. *standard*. Save this configuration to\n*mysql/persistent-volume-claim.yaml*.\n\n\n```yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: mysql-pv-claim-db\nspec:\n  storageClassName: standard\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n\n```\n\nRun the command *kubectl apply -f ./mysql/persistent-volume-claim.yaml* to \ncreate a persistent volume and persistent volume claim.\n\n\n## Putting it all together\n\nFinally, we will mount the volume that we have just claimed to our mysql server.\nSo, the final deployment file will be:\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mysql-database\nspec:\n  selector:\n    matchLabels:\n      app: mysql-database\n  strategy:\n    type: Recreate\n  template:\n    metadata:\n      labels:\n        app: mysql-database\n    spec:\n      containers:\n        - image: mysql:8.0\n          name: mysql-database\n          env:\n            - name: MYSQL_ROOT_PASSWORD\n              value: ${MYSQL_PASSWORD}\n            - name: MYSQL_USER\n              value: ${MYSQL_USERNAME}\n            - name: MYSQL_PASSWORD\n              value: ${MYSQL_PASSWORD}\n            - name: MYSQL_DATABASE\n              value: my_database\n          ports:\n            - containerPort: 3306\n              name: mysql-database\n          volumeMounts:\n            - name: mysql-persistent-storage-ebs\n              mountPath: /var/lib/mysql\n      volumes:\n        - name: mysql-persistent-storage-ebs\n          persistentVolumeClaim:\n            claimName: mysql-pv-claim-db\n\n```\n\nRunning the command *kubectl apply -f ./mysql/deployment.yaml* should update \nthe the previous MySQL server deployment with the new one which uses the newly\nprovisioned persistent volume.\n\nAny data saved in the mysql server will now be persistent across server \nrestarts.\n<br/>\n<br/>\n\n"}]